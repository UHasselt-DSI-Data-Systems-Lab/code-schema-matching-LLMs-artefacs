{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8685242c-0a11-4df1-a28f-a564cf8578b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import os\n",
    "from typing import Dict, List, Optional, Set\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "import textdistance\n",
    "\n",
    "from fm_matcher.utils.models import Attribute, Parameters, Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1a466-42f8-48f5-8c97-1b15dac1dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = pd.read_csv(\"benchmark/ground_truth.csv\")\n",
    "for side in (\"source\", \"target\"):\n",
    "    benchmark[[f\"{side}_schema\", f\"{side}_relation\", f\"{side}_attribute\"]] = benchmark[side].str.split(\".\", expand=True)\n",
    "    benchmark[side] = benchmark[side].str.lower()\n",
    "benchmark[\"benchmark\"] = True\n",
    "\n",
    "relation_combinations = benchmark[[\"source_relation\", \"target_relation\"]].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f483cb-8a3f-411c-8fb3-ade9ca6f103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.cache\n",
    "def get_description(schema: str, table: str, attribute: Optional[str] = None) -> str:\n",
    "    if attribute:\n",
    "        filename = f\"{schema}_{table}_{attribute}.txt\"\n",
    "    else:\n",
    "        filename = f\"{schema}_table_{table}.txt\"\n",
    "    filename_filter = lambda f: f.lower() == filename.lower()\n",
    "    filename = next(filter(filename_filter, os.listdir(\"schema_documentations\")))\n",
    "    with open(os.path.join(\"schema_documentations\", filename), \"r\") as desc_file:\n",
    "        description = desc_file.read()\n",
    "    return description\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "def get_attributes(schema: str, table: str) -> List[str]:\n",
    "    table_filter = lambda f: f.lower().startswith(f\"{schema}_{table}_\") and f.endswith(\".txt\")\n",
    "    extract_attr_name = lambda f: f[len(f\"{schema}_{table}_\"):-len(\".txt\")]\n",
    "    return [\n",
    "        extract_attr_name(attr_file)\n",
    "        for attr_file in filter(table_filter, os.listdir(\"schema_documentations/\"))\n",
    "    ]\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "def get_relation(schema: str, table: str) -> Relation:\n",
    "    schema, table = schema.lower(), table.lower()\n",
    "    description = get_description(schema, table)\n",
    "    attributes = [\n",
    "        Attribute(\n",
    "            name=attr_name.capitalize(),\n",
    "            description=get_description(schema, table, attr_name),\n",
    "        ) for attr_name in get_attributes(schema, table)\n",
    "    ]\n",
    "    return Relation(\n",
    "        name=table.capitalize(),\n",
    "        description=description,\n",
    "        attributes=attributes,\n",
    "    )\n",
    "\n",
    "\n",
    "parameters = [\n",
    "    Parameters(\n",
    "        source_relation=get_relation(\"mimic\", source),\n",
    "        target_relation=get_relation(\"omop\", target),\n",
    "    ) for source, target in relation_combinations\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05b13e-c926-4d2c-90df-0353bd34d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(s: str, n: int = 3) -> Set[str]:\n",
    "    # as by [Sun et al.](www.doi.org/10.12733/jics20105420)\n",
    "    full_s = f\"{'#' * (n-1)}{s}{'%' * (n-1)}\"\n",
    "    return {full_s[i:i+n] for i in range(len(full_s) - n + 1)}\n",
    "\n",
    "\n",
    "baseline_data = []\n",
    "for param in parameters:\n",
    "    for source, target in itertools.product(param.source_relation.attributes, param.target_relation.attributes):\n",
    "        source_attr = source.name.lower()\n",
    "        target_attr = target.name.lower()\n",
    "        baseline_data.append({\n",
    "            \"source\": f\"mimic.{param.source_relation.name}.{source.name}\".lower(),\n",
    "            \"source_relation\": param.source_relation.name,\n",
    "            \"source_attribute\": source.name.lower(),\n",
    "            \"target\": f\"omop.{param.target_relation.name}.{target.name}\".lower(),\n",
    "            \"target_relation\": param.target_relation.name,\n",
    "            \"target_attribute\": target.name.lower(),\n",
    "            \"jaro-winkler\": textdistance.jaro_winkler.normalized_similarity(source_attr, target_attr),\n",
    "            \"levenshtein\": textdistance.levenshtein.normalized_similarity(source_attr, target_attr),\n",
    "            \"monge-elkan\": textdistance.monge_elkan.normalized_similarity(source_attr, target_attr),\n",
    "            \"n-gram\": textdistance.sorensen.normalized_similarity(get_ngrams(source_attr, 3), get_ngrams(target_attr, 3)),\n",
    "        })\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline_data)\n",
    "baseline_df = baseline_df.merge(benchmark[[\"source\", \"target\", \"benchmark\"]], on=[\"source\", \"target\"], how=\"left\").copy()\n",
    "baseline_df[\"benchmark\"] = baseline_df[\"benchmark\"].fillna(False)\n",
    "baseline_df.to_csv(\"results/baseline_results.csv\", index=False)\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb93b7b5-e5bf-4c77-bbad-93d8e673cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(\n",
    "    layout={\n",
    "        \"width\": 1000,\n",
    "        \"height\": 600,\n",
    "        \"title\": \"Precision-Recall curve of different string similarity metrics.\",\n",
    "        \"yaxis\": {\"title\": \"precision\"},\n",
    "        \"xaxis\": {\"title\": \"recall\"},\n",
    "    }\n",
    ")\n",
    "    \n",
    "for metric in [\"jaro-winkler\", \"levenshtein\", \"monge-elkan\", \"n-gram\"]:\n",
    "    precision, recall, thresholds = precision_recall_curve(\n",
    "        baseline_df[\"benchmark\"],\n",
    "        baseline_df[metric],\n",
    "        pos_label=True,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=recall,\n",
    "            y=precision,\n",
    "            name=f\"{metric} (AUC: {auc(recall, precision):.2f})\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc4fb9-57cb-4617-9f23-75ab8cd3af05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
